{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "NinVT31dbNPp"
      ],
      "authorship_tag": "ABX9TyNg0IKZYXJowyi96FTndpCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristhianSeverino/Afiliados360/blob/En-Proceso/DataConfa_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visión 360 usuarios Confa**\n",
        "\n",
        "> Este Notebook es creacion de: **Cristhian Calle Severino**.\n",
        "\n",
        "\n",
        "\n",
        "*   **Github**: https://github.com/CristhianSeverino\n",
        "*   **Linkedin**: https://www.linkedin.com/in/cristhianandrescalleseverino/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Este proyecto es realizado Con el fin de demostrar un Procediminto de Gestion integral de data.\n",
        "\n",
        "**Incluye:**\n",
        "\n",
        "* Creacion de Datos sinteticos de usuarios de **Confa**, Esta gestion de datos sinteticos simula la optencion de data estructurada en bruto, via API o por pipeline de datos.\n",
        "\n",
        "* **ELT:** los datos son cargados en bruto en un bucket de AWS3, se Realiza Transformacion con **Pyspark** y **Glue**.\n",
        "\n",
        "* **Load/Carga** de Dataset transformado Para la ingesta de herramienta Bi.\n",
        "\n",
        "**Nota:** Para este proyecto Empleare **Locker Studio**. pero puede ser empleado **Power-Bi** o **Tablau**. app-Dash o de otros frameworks open-sourse.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0gDtEq37y6BE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalacción E Importación de Librerias**"
      ],
      "metadata": {
        "id": "NinVT31dbNPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker\n",
        "from faker import Faker\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMxPhG_40Vbd",
        "outputId": "e96588fe-9f11-4002-833c-791341e0b31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.12/dist-packages (37.6.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.12/dist-packages (from faker) (2025.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creación de Datos Sinteticos**\n",
        "* Los siguientes datos se generan en virtud de crear **tres tablas de dimensiones**. las cuales seran empleadas durante el proceso de ETL/ELT. para la creacion de **una tabla de hechos**.\n",
        "* los datos sinteticos fueron elaborados con base a una investigacion de mercado. de las estadistcias poblacionales de **Caldas** y la tipologia de **Servicios**. asi como **caracteristicas socioeconomicas** Observables en el publico objetivo de *Confa*.\n",
        "\n",
        "**Diviertete Explorando este Proyecto. Prospero día ☕**"
      ],
      "metadata": {
        "id": "Yb5bBp3pbUOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cofiguracion de Fake, ajustala Segun  las especifiaciones del dataset que deseas crear.\n",
        "#   * ten en cueta el publico y su comportamieento con los productos de la orgaizacion que deseas reccrear\n",
        "#   * Recuerda tener muy presemnte el modelo de negocio, su cultura e idenidad de marca\n",
        "fake= Faker('es_CO')\n",
        "Faker.seed(42)\n",
        "\n"
      ],
      "metadata": {
        "id": "k6w6t2bcyzJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2KAXn5myweR",
        "outputId": "2d58f1d0-114d-4431-cc57-3de61d944217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================   Datos Generados Exitosameente   ==============================\n",
            "           id                 nombre categoria                      correo  \\\n",
            "0  1000083810   María Marcela Torres         C  buitragostiven@example.org   \n",
            "1  1000047052  Francisco Rubén Ariza         C   cardozomyriam@example.net   \n",
            "2  1000089733    Elkin Sergio Torres         A         yenny13@example.net   \n",
            "3  1000032953          Ruth González         C     sebastian51@example.com   \n",
            "4  1000031385           Paola Ospina         A     arizavictor@example.net   \n",
            "\n",
            "                                           direccion fecha_nacimiento  \\\n",
            "0  Cr. 78 # 5-19\\nApartamento 1\\n688908\\nCimitarr...       1990-02-24   \n",
            "1  Carrera 35 # 5-23 Este\\nLocal 4\\n274131\\nSipí,...       1986-06-27   \n",
            "2  Carrera 153 # 28E-17\\nTorre 8 apartamento 722\\...       1958-07-10   \n",
            "3  Avenida Marco Palacios # 6-3 Este\\n688281\\nLan...       2004-12-16   \n",
            "4   Av. calle 53 # 8-95 Sur\\n158963\\nOtanche, Boyacá       1956-09-04   \n",
            "\n",
            "              telefono  \n",
            "0      (+57)3142351161  \n",
            "1         018003276483  \n",
            "2           3069166978  \n",
            "3  (+57) 320 957 01 54  \n",
            "4        301 509 83 93  \n",
            "======================================================================\n",
            "Descripción del data Frame:   .describe()\n",
            "======================================================================\n",
            "                 id\n",
            "count  1.000000e+05\n",
            "mean   1.000050e+09\n",
            "std    2.886772e+04\n",
            "min    1.000000e+09\n",
            "25%    1.000025e+09\n",
            "50%    1.000050e+09\n",
            "75%    1.000075e+09\n",
            "max    1.000100e+09\n",
            "======================================================================\n",
            "Informació del data Frame: .info()\n",
            "======================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 7 columns):\n",
            " #   Column            Non-Null Count   Dtype \n",
            "---  ------            --------------   ----- \n",
            " 0   id                100000 non-null  int64 \n",
            " 1   nombre            100000 non-null  object\n",
            " 2   categoria         100000 non-null  object\n",
            " 3   correo            100000 non-null  object\n",
            " 4   direccion         100000 non-null  object\n",
            " 5   fecha_nacimiento  100000 non-null  object\n",
            " 6   telefono          100000 non-null  object\n",
            "dtypes: int64(1), object(6)\n",
            "memory usage: 5.3+ MB\n",
            "None\n",
            "Datos Guardados en usuarios2024.csv\n"
          ]
        }
      ],
      "source": [
        "#===================================   Tabla 1   =============================================\n",
        "# Generar datos para un DataFrame\n",
        "datos = []\n",
        "ids_usados = set()\n",
        "while len(datos) < 100000:\n",
        "    id_candidato = fake.random_int(min=1000000000, max=1000100000)\n",
        "    if id_candidato not in ids_usados:\n",
        "        ids_usados.add(id_candidato)\n",
        "        datos.append({\n",
        "            'id': id_candidato,\n",
        "            'nombre':fake.name(),\n",
        "            'categoria' : fake.random_element(['A','B','C']),\n",
        "            'correo':fake.email(),\n",
        "            'direccion' : fake.address(),\n",
        "            'fecha_nacimiento' : fake.date_of_birth(minimum_age=18, maximum_age=75),\n",
        "            'telefono': fake.phone_number(),\n",
        "\n",
        "        })\n",
        "\n",
        "print(\"=\"*30+\"   Datos Generados Exitosameente   \"+\"=\"*30)\n",
        "# print(datos) # Commenting out printing all data to avoid large output\n",
        "\n",
        "#====================================   Crear un DataFrame con pandas   ================================================\n",
        "df= pd.DataFrame(datos)\n",
        "print(df.head())\n",
        "print(\"=\"*70)\n",
        "print(\"Descripción del data Frame:   .describe()\")\n",
        "print(\"=\"*70)\n",
        "print(df.describe())\n",
        "print(\"=\"*70)\n",
        "print(\"Informació del data Frame: .info()\")\n",
        "print(\"=\"*70)\n",
        "print(df.info())\n",
        "#================================================   Guardar en CSV   ==================================================\n",
        "df.to_csv('usuarios2024.csv', index=False, encoding='utf-8')\n",
        "print(\"Datos Guardados en usuarios2024.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#===================================   Tabla 2   =============================================\n",
        "\n",
        "# Extrae los IDs geneerados para el primer Data Frame\n",
        "\n",
        "ids_disponibles = df['id'].tolist()\n",
        "\n",
        "# Lista de servicios posibles\n",
        "servicios = ['Subsidios', 'Servicios Medicos','Plan Medicina Prepagada', 'Vacunación', 'Deporte y Acondicionamiento Fisico','Educación','Bibliotecas','Eventos Culturales',\n",
        "             'Centros Rcreacionales', 'Deportes','Creditos']\n",
        "#===========================   Generar datos para el segundo DataFrame (servicios_usados)   =============================\n",
        "datos_servicios = []\n",
        "num_registros = 200000\n",
        "\n",
        "# Asegurar que cada Id se use al menos una vez\n",
        "for id_afiliado in ids_disponibles:\n",
        "    datos_servicios.append({\n",
        "        'id' : id_afiliado,\n",
        "        'servicio' : fake.random_element(elements=servicios),\n",
        "        'fecha': fake.date_between(start_date=datetime(2024, 1, 1), end_date=datetime(2024, 12, 31))\n",
        "    })\n",
        "\n",
        "# Generar registros adicionales para alcanzar num_registros\n",
        "while len(datos_servicios) < num_registros:\n",
        "    datos_servicios.append({\n",
        "        'id' : random.choice(ids_disponibles),\n",
        "        'servicio' : fake.random_element(elements=servicios),\n",
        "        'fecha':fake.date_between(start_date=datetime(2024, 1, 1), end_date=datetime(2024, 12, 31))\n",
        "        })\n",
        "\n",
        "df_servicios = pd.DataFrame(datos_servicios)\n",
        "print(df_servicios.head())\n",
        "print(\"=\"*70)\n",
        "print(\"Descripción del data Frame:   .describe()\")\n",
        "print(\"=\"*70)\n",
        "print(df_servicios.describe())\n",
        "print(\"=\"*70)\n",
        "print(\"Informació del data Frame: .info()\")\n",
        "print(\"=\"*70)\n",
        "print(df_servicios.info())\n",
        "\n",
        "#================================================   Guardar en CSV   ==================================================\n",
        "df_servicios.to_csv('servicios_usados.csv', index=False, encoding='utf-8')\n",
        "print(\"Datos Guardados en servicios_usados.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TOqFSk62_Zr",
        "outputId": "4992bbdb-8379-43b6-d367-015bc6bc2b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id            servicio       fecha\n",
            "0  1000083810   Servicios Medicos  2024-01-08\n",
            "1  1000047052  Eventos Culturales  2024-04-24\n",
            "2  1000089733         Bibliotecas  2024-02-27\n",
            "3  1000032953           Subsidios  2024-04-12\n",
            "4  1000031385            Creditos  2024-10-11\n",
            "======================================================================\n",
            "Descripción del data Frame:   .describe()\n",
            "======================================================================\n",
            "                 id\n",
            "count  2.000000e+05\n",
            "mean   1.000050e+09\n",
            "std    2.888618e+04\n",
            "min    1.000000e+09\n",
            "25%    1.000025e+09\n",
            "50%    1.000050e+09\n",
            "75%    1.000075e+09\n",
            "max    1.000100e+09\n",
            "======================================================================\n",
            "Informació del data Frame: .info()\n",
            "======================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200000 entries, 0 to 199999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count   Dtype \n",
            "---  ------    --------------   ----- \n",
            " 0   id        200000 non-null  int64 \n",
            " 1   servicio  200000 non-null  object\n",
            " 2   fecha     200000 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 4.6+ MB\n",
            "None\n",
            "Datos Guardados en servicios_usados.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72b5e2c1",
        "outputId": "f8e09131-106c-429e-c3fa-e5e5e3f9e3bb"
      },
      "source": [
        "#===================================   Tabla 3   =============================================\n",
        "\n",
        "# Extrae los IDs geneerados para el primer Data Frame\n",
        "\n",
        "ids_disponibles = df['id'].tolist()\n",
        "\n",
        "# Lista de servicios posibles\n",
        "subsidios = ['Subsidio Familiar Monetario', 'Subsidio de Vivienda', 'Subsidio Educativo', 'Subsidio de Desempleo']\n",
        "#===========================   Generar datos para el segundo DataFrame (servicios_usados)   =============================\n",
        "datos_subsidios = []\n",
        "num_registros2 = 150000\n",
        "\n",
        "# Asegurar que cada Id se use al menos una vez\n",
        "for id_afiliado in ids_disponibles:\n",
        "    datos_subsidios.append({\n",
        "        'id' : id_afiliado,\n",
        "        'tipo_subsidio' : fake.random_element(elements=subsidios),\n",
        "        'monto': fake.random_int(min=100000, max=39000000),\n",
        "        'fecha': fake.date_between(start_date=datetime(2024, 1, 1), end_date=datetime(2024, 12, 31))\n",
        "    })\n",
        "\n",
        "# Generar registros adicionales para alcanzar num_registros\n",
        "while len(datos_subsidios) < num_registros2:\n",
        "    datos_subsidios.append({\n",
        "        'id' : random.choice(ids_disponibles),\n",
        "        'tipo_subsidio' : fake.random_element(elements=subsidios),\n",
        "        'monto': fake.random_int(min=100000, max=39000000),\n",
        "        'fecha':fake.date_between(start_date=datetime(2024, 1, 1), end_date=datetime(2024, 12, 31))\n",
        "        })\n",
        "\n",
        "df_subsidios = pd.DataFrame(datos_subsidios)\n",
        "print(df_subsidios.head())\n",
        "print(\"=\"*70)\n",
        "print(\"Descripción del data Frame:   .describe()\")\n",
        "print(\"=\"*70)\n",
        "print(df_subsidios.describe())\n",
        "print(\"=\"*70)\n",
        "print(\"Informació del data Frame: .info()\")\n",
        "print(\"=\"*70)\n",
        "print(df_subsidios.info())\n",
        "\n",
        "#================================================   Guardar en CSV   ==================================================\n",
        "df_subsidios.to_csv('subsidios_otorgados.csv', index=False, encoding='utf-8')\n",
        "print(\"Datos Guardados en subsidios_otorgados.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id          tipo_subsidio     monto       fecha\n",
            "0  1000083810  Subsidio de Desempleo   2661445  2024-10-07\n",
            "1  1000047052  Subsidio de Desempleo  29246634  2024-12-17\n",
            "2  1000089733   Subsidio de Vivienda  25316044  2024-03-18\n",
            "3  1000032953  Subsidio de Desempleo  33873993  2024-01-14\n",
            "4  1000031385   Subsidio de Vivienda  35285795  2024-07-13\n",
            "======================================================================\n",
            "Descripción del data Frame:   .describe()\n",
            "======================================================================\n",
            "                 id         monto\n",
            "count  1.500000e+05  1.500000e+05\n",
            "mean   1.000050e+09  1.955117e+07\n",
            "std    2.885007e+04  1.123615e+07\n",
            "min    1.000000e+09  1.010750e+05\n",
            "25%    1.000025e+09  9.820253e+06\n",
            "50%    1.000050e+09  1.951771e+07\n",
            "75%    1.000075e+09  2.929910e+07\n",
            "max    1.000100e+09  3.899986e+07\n",
            "======================================================================\n",
            "Informació del data Frame: .info()\n",
            "======================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150000 entries, 0 to 149999\n",
            "Data columns (total 4 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             150000 non-null  int64 \n",
            " 1   tipo_subsidio  150000 non-null  object\n",
            " 2   monto          150000 non-null  int64 \n",
            " 3   fecha          150000 non-null  object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 4.6+ MB\n",
            "None\n",
            "Datos Guardados en subsidios_otorgados.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extract And Load**\n",
        "\n",
        "> Se extraen los archivos del directorio local y se suben en bruto a AWS.\n",
        "\n",
        "* Se hace uso de un **Bucket S3 de AWS** Como data warehouse.\n"
      ],
      "metadata": {
        "id": "r9XKYdXpqty5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3\n",
        "!pip install awscli"
      ],
      "metadata": {
        "id": "F_Q-Qka5UpVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3a14a6-bc75-42bf-bc7f-bb69e187b78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (1.40.20)\n",
            "Requirement already satisfied: botocore<1.41.0,>=1.40.20 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.40.20)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from boto3) (0.13.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.20->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.20->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.20->boto3) (1.17.0)\n",
            "Requirement already satisfied: awscli in /usr/local/lib/python3.12/dist-packages (1.42.20)\n",
            "Requirement already satisfied: botocore==1.40.20 in /usr/local/lib/python3.12/dist-packages (from awscli) (1.40.20)\n",
            "Requirement already satisfied: docutils<=0.19,>=0.18.1 in /usr/local/lib/python3.12/dist-packages (from awscli) (0.19)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /usr/local/lib/python3.12/dist-packages (from awscli) (0.13.1)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.12/dist-packages (from awscli) (6.0.2)\n",
            "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /usr/local/lib/python3.12/dist-packages (from awscli) (0.4.6)\n",
            "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from awscli) (4.7.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from botocore==1.40.20->awscli) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore==1.40.20->awscli) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore==1.40.20->awscli) (2.5.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.40.20->awscli) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJjQZV4tw1pa",
        "outputId": "fe5f0333-9b4d-464e-e63c-52e9d1d3bde4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-29 01:13:25 aws-glue-assets-174856166333-us-east-2\n",
            "2025-08-28 22:05:30 vision-360-afiliados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# 1. Leer las credenciales desde los Secrets de Colab\n",
        "# Secretos de colab. Se ejecuta como variables de entorno por seguridad de los datos sensibles\n",
        "aws_access_key_id = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "aws_secret_access_key = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "region_name = userdata.get('AWS_REGION')\n",
        "\n",
        "\n",
        "# 2. Crear los archivos de configuración de AWS\n",
        "# Directorio y Archivo de Credenciales\n",
        "aws_dir = '/root/.aws'\n",
        "os.makedirs(aws_dir, exist_ok=True)\n",
        "\n",
        "# Escribir el archivo 'credentials'\n",
        "with open(os.path.join(aws_dir, 'credentials'), 'w') as f:\n",
        "    f.write(f'[default]\\n')\n",
        "    f.write(f'aws_access_key_id = {aws_access_key_id}\\n')\n",
        "    f.write(f'aws_secret_access_key = {aws_secret_access_key}\\n')\n",
        "\n",
        "# Escribir el archivo 'config'\n",
        "with open(os.path.join(aws_dir, 'config'), 'w') as f:\n",
        "    f.write(f'[default]\\n')\n",
        "    f.write(f'region = {region_name}\\n')\n",
        "\n",
        "print(\"Archivos de configuración de AWS creados exitosamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNgTHLFV8vpd",
        "outputId": "3f71f389-14b2-46d9-ab7e-0a71a3eebef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos de configuración de AWS creados exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55G6wmbv-ryN",
        "outputId": "e7109be5-ce5d-420e-ceda-0433862ef8b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-08-29 01:13:25 aws-glue-assets-174856166333-us-east-2\n",
            "2025-08-28 22:05:30 vision-360-afiliados\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3"
      ],
      "metadata": {
        "id": "q-7H2MbKgVnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura tu bucket y credenciales\n",
        "bucket_name = 'vision-360-afiliados'\n",
        "s3 = boto3.client('s3')\n",
        "\n",
        "def upload_to_s3(local_file, s3_path):\n",
        "    s3.upload_file(local_file, bucket_name, s3_path)\n",
        "    print(f\"Subido {local_file} a s3://{bucket_name}/{s3_path}\")\n",
        "\n",
        "upload_to_s3('usuarios2024.csv', 'landing-zone/usuarios2024.csv')\n",
        "upload_to_s3('servicios_usados.csv', 'landing-zone/servicios_usados.csv')\n",
        "upload_to_s3('subsidios_otorgados.csv', 'landing-zone/subsidios_otorgados.csv')"
      ],
      "metadata": {
        "id": "BXO0TWWQqrKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82ef3fa-092c-4304-ff9f-cf25595c10f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subido usuarios2024.csv a s3://vision-360-afiliados/landing-zone/usuarios2024.csv\n",
            "Subido servicios_usados.csv a s3://vision-360-afiliados/landing-zone/servicios_usados.csv\n",
            "Subido subsidios_otorgados.csv a s3://vision-360-afiliados/landing-zone/subsidios_otorgados.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transform**"
      ],
      "metadata": {
        "id": "r34EeI-4Gq75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, lit, when, isnull, to_date\n",
        "import os\n",
        "\n",
        "# Función para validar y separar\n",
        "def validate_and_split(df, rules, table_name):\n",
        "    # Inicializa una columna de errores con valores nulos\n",
        "    error_col = lit(None).alias(\"error\")\n",
        "\n",
        "    # Crea una columna de errores vacía en el DataFrame\n",
        "    df_with_errors = df.withColumn(\"error\", error_col)\n",
        "\n",
        "    # Itera sobre las reglas para agregar los errores\n",
        "    for condition, error_msg in rules:\n",
        "        df_with_errors = df_with_errors.withColumn(\n",
        "            \"error\",\n",
        "            when(condition,\n",
        "                 when(col(\"error\").isNull(), lit(error_msg)).otherwise(col(\"error\") + \"; \" + lit(error_msg))\n",
        "            ).otherwise(col(\"error\"))\n",
        "        )\n",
        "\n",
        "    good_df = df_with_errors.filter(col(\"error\").isNull()).drop(\"error\")\n",
        "    bad_df = df_with_errors.filter(col(\"error\").isNotNull())\n",
        "\n",
        "    # Crea los directorios si no existen\n",
        "    os.makedirs(raw_clean, exist_ok=True)\n",
        "    os.makedirs(raw_quarantine, exist_ok=True)\n",
        "\n",
        "    good_df.write.mode(\"overwrite\").parquet(f\"{raw_clean}{table_name}.parquet\")\n",
        "    bad_df.write.mode(\"overwrite\").parquet(f\"{raw_quarantine}{table_name}_bad.parquet\")\n",
        "    print(f\"Procesado {table_name}: Buenos={good_df.count()}, Malos={bad_df.count()}\")\n",
        "\n",
        "\n",
        "# Resto del script se mantiene igual\n",
        "# Iniciar Session en PySpark\n",
        "spark = SparkSession.builder.appName(\"DataQualityGate\").getOrCreate()\n",
        "\n",
        "# Rutas locales (simulando S3)\n",
        "landing_zone = \"/content/\"\n",
        "raw_clean = \"/content/raw-zone/clean/\"\n",
        "raw_quarantine = \"/content/raw-zone/quarantine/\"\n",
        "\n",
        "# Resto de tu código para leer y validar los dataframes\n",
        "df_afiliados = spark.read.csv(f\"{landing_zone}usuarios2024.csv\", header=True, inferSchema=True)\n",
        "rules_afiliados = [\n",
        "    (to_date(col(\"fecha_nacimiento\"), \"yyyy-MM-dd\").isNull(), \"Fecha de nacimiento inválida\"),\n",
        "    (isnull(col(\"telefono\")), \"Teléfono nulo\")\n",
        "]\n",
        "validate_and_split(df_afiliados, rules_afiliados, \"afiliados\")\n",
        "\n",
        "df_servicios = spark.read.csv(f\"{landing_zone}servicios_usados.csv\", header=True, inferSchema=True)\n",
        "rules_servicios = [\n",
        "    (isnull(col(\"id\")), \"ID Nula\"),\n",
        "    (isnull(col(\"servicio\")), \"Servicio nulo\"),\n",
        "    (to_date(col(\"fecha\"), \"yyyy-MM-dd\").isNull(), \"Fecha inválida\")\n",
        "]\n",
        "validate_and_split(df_servicios, rules_servicios, \"servicios_usados\")\n",
        "\n",
        "df_subsidios = spark.read.csv(f\"{landing_zone}subsidios_otorgados.csv\", header=True, inferSchema=True)\n",
        "rules_subsidios = [\n",
        "    (col(\"monto\") <= 0, \"Monto <= 0\"),\n",
        "    (to_date(col(\"fecha\"), \"yyyy-MM-dd\").isNull(), \"Fecha inválida\")\n",
        "]\n",
        "validate_and_split(df_subsidios, rules_subsidios, \"subsidios\")\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ-vUxbZSa8t",
        "outputId": "fd383bef-c344-4a06-aad0-af08fb7e4013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Procesado afiliados: Buenos=350113, Malos=0\n",
            "Procesado servicios_usados: Buenos=200000, Malos=0\n",
            "Procesado subsidios: Buenos=150000, Malos=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Verifica la Crreacion de los CSV en el icono de carpeta.costado izquiero de colab***"
      ],
      "metadata": {
        "id": "bMc31ythgMZH"
      }
    }
  ]
}